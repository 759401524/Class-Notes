{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、导入pandas库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、导入数据集airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_csv = 'https://raw.githubusercontent.com/zhoujinhai/pandasData/master/airlines.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、将数据集存入一个名为airlines的数据框内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines = pd.read_csv(airlines_csv, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4、查看后面5行行内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       airline  avail_seat_km_per_week  incidents_85_99  \\\n",
      "51       United / Continental*              7139291291               19   \n",
      "52  US Airways / America West*              2455687887               16   \n",
      "53            Vietnam Airlines               625084918                7   \n",
      "54             Virgin Atlantic              1005248585                1   \n",
      "55             Xiamen Airlines               430462962                9   \n",
      "\n",
      "    fatal_accidents_85_99  fatalities_85_99  incidents_00_14  \\\n",
      "51                      8               319               14   \n",
      "52                      7               224               11   \n",
      "53                      3               171                1   \n",
      "54                      0                 0                0   \n",
      "55                      1                82                2   \n",
      "\n",
      "    fatal_accidents_00_14  fatalities_00_14  \n",
      "51                      2               109  \n",
      "52                      2                23  \n",
      "53                      0                 0  \n",
      "54                      0                 0  \n",
      "55                      0                 0  \n"
     ]
    }
   ],
   "source": [
    "print(airlines.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5、观察数据集的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56 entries, 0 to 55\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   airline                 56 non-null     object\n",
      " 1   avail_seat_km_per_week  56 non-null     int64 \n",
      " 2   incidents_85_99         56 non-null     int64 \n",
      " 3   fatal_accidents_85_99   56 non-null     int64 \n",
      " 4   fatalities_85_99        56 non-null     int64 \n",
      " 5   incidents_00_14         56 non-null     int64 \n",
      " 6   fatal_accidents_00_14   56 non-null     int64 \n",
      " 7   fatalities_00_14        56 non-null     int64 \n",
      "dtypes: int64(7), object(1)\n",
      "memory usage: 3.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(airlines.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6、打印数据集大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 8)\n"
     ]
    }
   ],
   "source": [
    "print(airlines.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7、打印出全部的列名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['airline', 'avail_seat_km_per_week', 'incidents_85_99',\n",
      "       'fatal_accidents_85_99', 'fatalities_85_99', 'incidents_00_14',\n",
      "       'fatal_accidents_00_14', 'fatalities_00_14'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(airlines.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================================\n",
    "真实数据集的异常值检测简介\n",
    "====================================\n",
    "\n",
    "此示例介绍了对真实数据集进行鲁棒协方差估计的必须性。(鲁棒的意思是足够稳定，绝不过拟合。)\n",
    "它对于异常检测(离群值检测)和更好地理解数据结构都是有用的。\n",
    "\n",
    "我们从波士顿住房数据集中选择了两组两个变量的数据子集，\n",
    "以说明可以使用几种离群值检测工具进行哪些分析。\n",
    "出于可视化的目的，我们使用的是2维示例，但是应该指出的是，在高维度上事情并非那么简单。\n",
    "\n",
    "在下面的两个示例来看，主要结论是经验协方差估计(作为一种非稳健的估计)\n",
    "受观测的异构结构的影响很大。尽管鲁棒的协方差估计能够集中于数据分布的主要模式，\n",
    "但它假定数据应该是高斯分布的，从而产生了对数据结构的某种有偏估计，不过在一定程度上还算准确。\n",
    "One-Class SVM不假设数据分布的任何参数形式，因此可以更好地对数据的复杂形状进行建模。\n",
    "\n",
    "第一个例子\n",
    "-------------\n",
    "第一个示例说明了当另外一个簇存在时，鲁棒的协方差估计如何帮助集中在相关簇上。\n",
    "在这里，许多观察结果被混淆为一个，让经验协方差估计效果变差。\n",
    "当然，某些筛选工具能指出存在两个聚类(支持向量机，高斯混合模型，单变量离群值检测……)。\n",
    "但是，如果这是一个高维度的例子，那么所有这些都不容易被应用。\n",
    "\n",
    "第二个例子\n",
    "-------------\n",
    "第二个示例显示了最小协方差鲁棒估计器专注于数据分布的主要模式的能力：\n",
    "尽管由于香蕉形分布而难以估算协方差，但位置似乎已得到很好的估计。\n",
    "无论如何，我们可以消除一些较远的离群点。 One-Class SVM能够捕获真实的数据结构，\n",
    "但是困难在于如何调整其核带宽参数，以便在数据散布矩阵的形状和过滤合数据的风险之间取得良好的折衷。\n",
    "\"\"\"\n",
    "\n",
    "# Author: Virgile Fritsch <virgile.fritsch@inria.fr>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# 载入此项目所需要的库\n",
    "import numpy as np\n",
    "# 椭圆模型拟合(EllipticEnvelope),它能拟合出数据的稳健协方差估计，从而为中心数据点拟合出一个椭圆，忽略不和该中心模式相关的点\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM  # 单类支持向量机\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "from sklearn.datasets import load_boston  # 从 sklearn 数据集中导入波士顿房价数据\n",
    "\n",
    "# 获取数据 取数据集里的两个变量，这两个变量的观测组成两类。\n",
    "X1 = load_boston()['data'][:, [8, 10]]  # 将数据分成两个集群\n",
    "X2 = load_boston()['data'][:, [5, 12]]  # 香蕉形\n",
    "\n",
    "# 定义要使用的分类器对象 classifiers, 它是一个字典型，\n",
    "# 由 Empirical Covariance, Robust Covariance, 单类支持向量机 OCSVM 三个分类器组成。\n",
    "# 最小协方差决定（Minimum Covariance Determinant）这个想法是找出一个给定比例（h）的 “好” 观察值，它们不是离群值，\n",
    "# 且可以计算其经验协方差矩阵。 然后将该经验协方差矩阵重新缩放以补偿所执行的观察选择（”consistency step(一致性步骤)”）。\n",
    "# 计算完最小协方差决定估计器后，可以根据其马氏距离（Mahalanobis distance）给出观测值的权重, 得到数据集的协方差矩阵的重新加权估计（”reweighting step(重新加权步骤)”）\n",
    "classifiers = {\n",
    "    \"Empirical Covariance\": EllipticEnvelope(  # EmpiricalCovariance 是基于最大似然协方差估计的算法\n",
    "        support_fraction=1.,  # 支持原始MCD(最小协方差行列式)估算的点数比例\n",
    "        contamination=0.261),  # 数据集的污染量，即数据集中异常值的比例。\n",
    "    # Robust Covariance是基于最小协方差行列式的算法，是鲁棒协方差估计。\n",
    "    \"Robust Covariance (Minimum Covariance Determinant)\":\n",
    "    EllipticEnvelope(contamination=0.261),\n",
    "        \"OCSVM\": OneClassSVM(nu=0.261,  # nu训练误差分数的上限，支持向量分数的下限\n",
    "                             gamma=0.05)}  # gamma 内核系数\n",
    "colors = ['m', 'g', 'b']\n",
    "legend1 = {}\n",
    "legend2 = {}\n",
    "\n",
    "# 使用定义的三个分类器，确定异常点检测边界\n",
    "# scikit-learn项目提供了一套可用于新奇点或离群点检测的机器学习工具。\n",
    "# 该策略是以无监督的方式学习数据中的对象来实现的: estimator.fit(X_train)\n",
    "# 然后可以使用 decision_function 方法将新观测值归为内围点或离群点: estimator.decision_function(X_test)\n",
    "# 内围点被标记为1，而离群点被标记为-1。 预测方法在估计器计算出的原始评分函数上使用一个阈值。\n",
    "# 这个阈值可以由参数contamination控制。\n",
    "# numpy.meshgrid()从坐标向量中返回坐标矩阵\n",
    "# numpy.linspace 函数用于创建一个一维数组，数组是一个等差数列构成的\n",
    "# numpy.linspace(start, stop, num) 目的是在start-stop之间生成num个数\n",
    "# numpy.c_是按行连接两个矩阵，就是把两矩阵左右相加，要求行数相等\n",
    "xx1, yy1 = np.meshgrid(np.linspace(-8, 28, 500), np.linspace(3, 40, 500))\n",
    "xx2, yy2 = np.meshgrid(np.linspace(3, 10, 500), np.linspace(-5, 45, 500))\n",
    "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "    plt.figure(1)\n",
    "    clf.fit(X1)  # 模型拟合\n",
    "    Z1 = clf.decision_function(  # decision_function代表的是参数实例到各个类所代表的超平面的距离\n",
    "        np.c_[xx1.ravel(), yy1.ravel()])\n",
    "    Z1 = Z1.reshape(xx1.shape)  # 将Z1的维度指定为xx1的维度\n",
    "    legend1[clf_name] = plt.contour(  # 绘制等高线\n",
    "        xx1, yy1, Z1,  # 使用 xx1 和 yy1 绘制 Z1 的等高线图，指定 Z1 中各值的 x 和 y 坐标\n",
    "        levels=[0],  # levels表示等高线的密集程度，如果是0，则图像被一分为二\n",
    "        linewidths=2,  # 线的宽度\n",
    "        colors=colors[i])  # 标签的颜色\n",
    "    plt.figure(2)\n",
    "\n",
    "    clf.fit(X2)\n",
    "    Z2 = clf.decision_function(np.c_[xx2.ravel(), yy2.ravel()])\n",
    "    Z2 = Z2.reshape(xx2.shape)\n",
    "    legend2[clf_name] = plt.contour(  # 绘制等高线\n",
    "        xx2, yy2, Z2,  # 使用 xx2 和 yy2 绘制 Z2 的等高线图，指定 Z2 中各值的 x 和 y 坐标\n",
    "        levels=[0], linewidths=2, colors=colors[i])\n",
    "\n",
    "legend1_values_list = list(legend1.values())\n",
    "legend1_keys_list = list(legend1.keys())\n",
    "\n",
    "# 画出结果图，我们会看到一个明显异常的观测点。\n",
    "# 使用plt.figure定义一个图像窗口：编号为1；\n",
    "# 使用plt.title定义标题；\n",
    "# 使用plt.scatter绘制散点，点的颜色属性(color)为黑色；\n",
    "# 使用plt.annotate绘制注解；\n",
    "# 使用plt.xlim, plt.ylim设置坐标轴的取值范围;\n",
    "# 使用plt.legend绘制图例；\n",
    "# 使用plt.xlabel, plt.ylabel定义标签\n",
    "plt.figure(1)  # two clusters\n",
    "plt.title(\"Outlier detection on a real data set (boston housing)\")  # 标题\n",
    "plt.scatter(X1[:, 0], X1[:, 1], color='black')  # 绘制散点\n",
    "bbox_args = dict(boxstyle=\"round\", fc=\"0.8\")\n",
    "arrow_args = dict(arrowstyle=\"->\")\n",
    "# 绘制注解\n",
    "plt.annotate(\"several confounded points\",  # 注释文本内容\n",
    "             xy=(24, 19),  # 被注释的坐标点(箭头点所在的坐标位置)\n",
    "             xycoords=\"data\",  # **coords 指定坐标\n",
    "             textcoords=\"data\",  # data：使用被注释对象的坐标系统(默认)\n",
    "             xytext=(13, 10),  # 注释文字的坐标位置\n",
    "             bbox=bbox_args,  # 为注释文本添加边框\n",
    "             arrowprops=arrow_args)  # 设置指向箭头的参数,参数类型为字典dict\n",
    "# 设置坐标轴的取值范围\n",
    "plt.xlim((xx1.min(), xx1.max()))\n",
    "plt.ylim((yy1.min(), yy1.max()))\n",
    "# 设置 legend 图例\n",
    "plt.legend((legend1_values_list[0].collections[0],  # handles参数，用于指定图例上面的图形\n",
    "            legend1_values_list[1].collections[0],\n",
    "            legend1_values_list[2].collections[0]),\n",
    "           (legend1_keys_list[0], legend1_keys_list[1],\n",
    "            legend1_keys_list[2]),  # labels参数，图例上图形对应的标签\n",
    "           loc=\"upper center\",  # 图例的位置\n",
    "           prop=matplotlib.font_manager.FontProperties(size=12))  # 图例的字体属性\n",
    "# 设置坐标轴的标签label\n",
    "plt.ylabel(\"accessibility to radial highways\")\n",
    "plt.xlabel(\"pupil-teacher ratio by town\")\n",
    "\n",
    "legend2_values_list = list(legend2.values())\n",
    "legend2_keys_list = list(legend2.keys())\n",
    "\n",
    "# 新建一个名叫 Figure2的画图窗口\n",
    "plt.figure(2)  # \"banana\" shape\n",
    "plt.title(\"Outlier detection on a real data set (boston housing)\")  # 标题\n",
    "plt.scatter(X2[:, 0], X2[:, 1], color='black')  # 绘制散点\n",
    "# 设置坐标轴的取值范围\n",
    "plt.xlim((xx2.min(), xx2.max()))\n",
    "plt.ylim((yy2.min(), yy2.max()))\n",
    "# 设置 legend 图例\n",
    "plt.legend((legend2_values_list[0].collections[0],  # handles参数，用于指定图例上面的图形\n",
    "            legend2_values_list[1].collections[0],\n",
    "            legend2_values_list[2].collections[0]),\n",
    "           (legend2_keys_list[0], legend2_keys_list[1],\n",
    "            legend2_keys_list[2]),  # labels参数，图例上图形对应的标签\n",
    "           loc=\"upper center\",  # loc表示位置\n",
    "           prop=matplotlib.font_manager.FontProperties(size=12))  # prop字体参数\n",
    "# 设置坐标轴的标签label\n",
    "plt.ylabel(\"% lower status of the population\")\n",
    "plt.xlabel(\"average number of rooms per dwelling\")\n",
    "\n",
    "# 显示\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda926f92ea88cc4e2a9261c74aed2fab1e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
