{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas 实例1\n",
    " Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1.0\n",
      "2    2.0\n",
      "3    4.0\n",
      "4    NaN\n",
      "5    7.0\n",
      "6    9.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 4, np.nan, 7, 9], index=[1, 2, 3, 4, 5, 6])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1.0\n",
      "2    2.0\n",
      "3    4.0\n",
      "4    NaN\n",
      "5    7.0\n",
      "6    9.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 4, np.nan, 7, 9], [1, 2, 3, 4, 5, 6])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas 实例2\n",
    "DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C\n",
      "a  0.597197 -0.966442 -1.043123\n",
      "b -0.703220  1.020589  0.550509\n",
      "c -0.308820 -0.898961 -0.745755\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(3, 3),\n",
    "                  index=list('abc'),\n",
    "                  columns=list('ABC'))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C\n",
      "a  1.131269  1.179064  0.203318\n",
      "b  1.795651  0.363998 -0.198378\n",
      "c  0.519086  0.396109 -1.141831\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(3, 3),\n",
    "                  index=['a', 'b', 'c'],\n",
    "                  columns=['A', 'B', 'C'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas 实例3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C    D\n",
      "0  1  1  3  foo\n",
      "1  1  2  3  foo\n",
      "2  1  3  3  foo\n",
      "3  1  4  3  foo\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'A': 1,\n",
    "    'B': pd.Series([1, 2, 3, 4], index=list(range(4))),\n",
    "    'C': np.array([3] * 4, dtype='int32'),\n",
    "    'D': 'foo'\n",
    "})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C    D\n",
      "0  1  1  3  foo\n",
      "1  1  2  3  foo\n",
      "2  1  3  3  foo\n",
      "3  1  4  3  foo\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict({\n",
    "    'A': 1,\n",
    "    'B': pd.Series([1, 2, 3, 4], index=list(range(4))),\n",
    "    'C': np.array([3] * 4, dtype='int32'),\n",
    "    'D': 'foo'\n",
    "})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A', 'B', 'C', 'D'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1, 2, 3], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 3 'foo']\n",
      " [1 2 3 'foo']\n",
      " [1 3 3 'foo']\n",
      " [1 4 3 'foo']]\n"
     ]
    }
   ],
   "source": [
    "print(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         A         B    C\n",
      "count  4.0  4.000000  4.0\n",
      "mean   1.0  2.500000  3.0\n",
      "std    0.0  1.290994  0.0\n",
      "min    1.0  1.000000  3.0\n",
      "25%    1.0  1.750000  3.0\n",
      "50%    1.0  2.500000  3.0\n",
      "75%    1.0  3.250000  3.0\n",
      "max    1.0  4.000000  3.0\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3\n",
      "A    1    1    1    1\n",
      "B    1    2    3    4\n",
      "C    3    3    3    3\n",
      "D  foo  foo  foo  foo\n"
     ]
    }
   ],
   "source": [
    "print(df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C    D\n",
      "0  1  1  3  foo\n",
      "1  1  2  3  foo\n"
     ]
    }
   ],
   "source": [
    "print(df[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C    D\n",
      "0  1  1  3  foo\n",
      "1  1  2  3  foo\n",
      "2  1  3  3  foo\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  1\n",
      "1  1  2\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0:2, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1   2   3   4 python\n",
      "0  5   6   7   8   java\n",
      "1  9  10  11  12    c++\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data.txt')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0   1   2   3       4\n",
      "0  1   2   3   4  python\n",
      "1  5   6   7   8    java\n",
      "2  9  10  11  12     c++\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data.txt', header=None)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name  a   b   c   d\n",
      "0  python  1   2   3   4\n",
      "1    java  5   6   7   8\n",
      "2     c++  9  10  11  12\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data1.txt', sep='\\s+')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  python  1   2   3   4\n",
      "0   java  5   6   7   8\n",
      "1    c++  9  10  11  12\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data1.txt', sep='\\s+', skiprows=[0])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================================\n",
    "真实数据集的异常值检测简介\n",
    "====================================\n",
    "\n",
    "此示例介绍了对真实数据集进行鲁棒协方差估计的必须性。(鲁棒的意思是足够稳定，绝不过拟合。)\n",
    "它对于异常检测(离群值检测)和更好地理解数据结构都是有用的。\n",
    "\n",
    "我们从波士顿住房数据集中选择了两组两个变量的数据子集，\n",
    "以说明可以使用几种离群值检测工具进行哪些分析。\n",
    "出于可视化的目的，我们使用的是2维示例，但是应该指出的是，在高维度上事情并非那么简单。\n",
    "\n",
    "在下面的两个示例来看，主要结论是经验协方差估计(作为一种非稳健的估计)\n",
    "受观测的异构结构的影响很大。尽管鲁棒的协方差估计能够集中于数据分布的主要模式，\n",
    "但它假定数据应该是高斯分布的，从而产生了对数据结构的某种有偏估计，不过在一定程度上还算准确。\n",
    "One-Class SVM不假设数据分布的任何参数形式，因此可以更好地对数据的复杂形状进行建模。\n",
    "\n",
    "第一个例子\n",
    "-------------\n",
    "第一个示例说明了当另外一个簇存在时，鲁棒的协方差估计如何帮助集中在相关簇上。\n",
    "在这里，许多观察结果被混淆为一个，让经验协方差估计效果变差。\n",
    "当然，某些筛选工具能指出存在两个聚类(支持向量机，高斯混合模型，单变量离群值检测……)。\n",
    "但是，如果这是一个高维度的例子，那么所有这些都不容易被应用。\n",
    "\n",
    "第二个例子\n",
    "-------------\n",
    "第二个示例显示了最小协方差鲁棒估计器专注于数据分布的主要模式的能力：\n",
    "尽管由于香蕉形分布而难以估算协方差，但位置似乎已得到很好的估计。\n",
    "无论如何，我们可以消除一些较远的离群点。 One-Class SVM能够捕获真实的数据结构，\n",
    "但是困难在于如何调整其核带宽参数，以便在数据散布矩阵的形状和过滤合数据的风险之间取得良好的折衷。\n",
    "\"\"\"\n",
    "\n",
    "# Author: Virgile Fritsch <virgile.fritsch@inria.fr>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# 载入此项目所需要的库\n",
    "import numpy as np\n",
    "# 椭圆模型拟合,它能拟合出数据的稳健协方差估计，从而为中心数据点拟合出一个椭圆，忽略不和该中心模式相关的点\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM  # 单类支持向量机\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "from sklearn.datasets import load_boston  # 从 sklearn 数据集中导入波士顿房价数据\n",
    "\n",
    "# 获取数据 取数据集里的两个变量，这两个变量的观测组成两类。\n",
    "X1 = load_boston()['data'][:, [8, 10]]  # 将数据分成两个集群\n",
    "X2 = load_boston()['data'][:, [5, 12]]  # 香蕉形\n",
    "\n",
    "# 定义要使用的分类器对象classifiers, 它是一个字典型，\n",
    "# 由Empirical Covariance, Robust Covariance, 单类支持向量机 OCSVM 三个分类器组成。\n",
    "classifiers = {\n",
    "    \"Empirical Covariance\": EllipticEnvelope(  # EmpiricalCovariance是基于最大似然协方差估计的算法\n",
    "        support_fraction=1.,  # 支持原始MCD(最小协方差行列式)估算的点数比例\n",
    "        contamination=0.261),  # 数据集的污染量，即数据集中异常值的比例。\n",
    "    # Robust Covariance是基于最小协方差行列式的算法，是鲁棒协方差估计。\n",
    "    \"Robust Covariance (Minimum Covariance Determinant)\":\n",
    "    EllipticEnvelope(contamination=0.261),\n",
    "        \"OCSVM\": OneClassSVM(nu=0.261,  # 训练误差分数的上限，支持向量分数的下限\n",
    "                             gamma=0.05)}  # 内核系数\n",
    "colors = ['m', 'g', 'b']\n",
    "legend1 = {}\n",
    "legend2 = {}\n",
    "\n",
    "# 使用定义的三个分类器，确定异常点检测边界\n",
    "# ny.meshgrid()从坐标向量中返回坐标矩阵\n",
    "# np.linspace 函数用于创建一个一维数组，数组是一个等差数列构成的\n",
    "# np.linspace(start, stop, num) 目的是在start-stop之间生成num个数\n",
    "# np.c_是按行连接两个矩阵，就是把两矩阵左右相加，要求行数相等\n",
    "xx1, yy1 = np.meQshgrid(np.linspace(-8, 28, 500), np.linspace(3, 40, 500))\n",
    "xx2, yy2 = np.meshgrid(np.linspace(3, 10, 500), np.linspace(-5, 45, 500))\n",
    "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "    plt.figure(1)\n",
    "    clf.fit(X1)  # 模型拟合\n",
    "    Z1 = clf.decision_function(  # decision_function代表的是参数实例到各个类所代表的超平面的距离\n",
    "        np.c_[xx1.ravel(), yy1.ravel()])\n",
    "    Z1 = Z1.reshape(xx1.shape)  # 将Z1的维度指定为xx1的维度\n",
    "    legend1[clf_name] = plt.contour(  # 绘制等高线\n",
    "        xx1, yy1, Z1,  # 使用 xx1 和 yy1 绘制 Z1 的等高线图，指定 Z1 中各值的 x 和 y 坐标\n",
    "        levels=[0],  # 确定轮廓线/区域的数量和位置。\n",
    "        linewidths=2,  # 线的宽度\n",
    "        colors=colors[i])  # 标签的颜色\n",
    "    plt.figure(2)\n",
    "\n",
    "    clf.fit(X2)\n",
    "    Z2 = clf.decision_function(np.c_[xx2.ravel(), yy2.ravel()])\n",
    "    Z2 = Z2.reshape(xx2.shape)\n",
    "    legend2[clf_name] = plt.contour(  # 绘制等高线\n",
    "        xx2, yy2, Z2,  # 使用 xx2 和 yy2 绘制 Z2 的等高线图，指定 Z2 中各值的 x 和 y 坐标\n",
    "        levels=[0], linewidths=2, colors=colors[i])\n",
    "\n",
    "legend1_values_list = list(legend1.values())\n",
    "legend1_keys_list = list(legend1.keys())\n",
    "\n",
    "# 画出结果图，我们会看到一个明显异常的观测点。\n",
    "# 新建一个名叫 Figure1的画图窗口\n",
    "plt.figure(1)  # two clusters\n",
    "plt.title(\"Outlier detection on a real data set (boston housing)\")  # 标题\n",
    "plt.scatter(X1[:, 0], X1[:, 1], color='black')  # 绘制散点\n",
    "bbox_args = dict(boxstyle=\"round\", fc=\"0.8\")\n",
    "arrow_args = dict(arrowstyle=\"->\")\n",
    "# 绘制注解\n",
    "plt.annotate(\"several confounded points\",  # 注释文本内容\n",
    "             xy=(24, 19),  # 被注释的坐标点(箭头点所在的坐标位置)\n",
    "             xycoords=\"data\",  # **coords 指定坐标\n",
    "             textcoords=\"data\",  # data：使用被注释对象的坐标系统(默认)\n",
    "             xytext=(13, 10),  # 注释文字的坐标位置\n",
    "             bbox=bbox_args,  # 为注释文本添加边框\n",
    "             arrowprops=arrow_args)  # 设置指向箭头的参数,参数类型为字典dict\n",
    "# 设置坐标轴的取值范围\n",
    "plt.xlim((xx1.min(), xx1.max()))\n",
    "plt.ylim((yy1.min(), yy1.max()))\n",
    "# 设置 legend 图例\n",
    "plt.legend((legend1_values_list[0].collections[0],  # handles参数，用于指定图例上面的图形\n",
    "            legend1_values_list[1].collections[0],\n",
    "            legend1_values_list[2].collections[0]),\n",
    "           (legend1_keys_list[0], legend1_keys_list[1],\n",
    "            legend1_keys_list[2]),  # labels参数，图例上图形对应的标签\n",
    "           loc=\"upper center\",  # 图例的位置\n",
    "           prop=matplotlib.font_manager.FontProperties(size=12))  # 图例的字体属性\n",
    "# 设置坐标轴的标签label\n",
    "plt.ylabel(\"accessibility to radial highways\")\n",
    "plt.xlabel(\"pupil-teacher ratio by town\")\n",
    "\n",
    "legend2_values_list = list(legend2.values())\n",
    "legend2_keys_list = list(legend2.keys())\n",
    "\n",
    "# 新建一个名叫 Figure2的画图窗口\n",
    "plt.figure(2)  # \"banana\" shape\n",
    "plt.title(\"Outlier detection on a real data set (boston housing)\")  # 标题\n",
    "plt.scatter(X2[:, 0], X2[:, 1], color='black')  # 绘制散点\n",
    "# 设置坐标轴的取值范围\n",
    "plt.xlim((xx2.min(), xx2.max()))\n",
    "plt.ylim((yy2.min(), yy2.max()))\n",
    "# 设置 legend 图例\n",
    "plt.legend((legend2_values_list[0].collections[0],  # handles参数，用于指定图例上面的图形\n",
    "            legend2_values_list[1].collections[0],\n",
    "            legend2_values_list[2].collections[0]),\n",
    "           (legend2_keys_list[0], legend2_keys_list[1],\n",
    "            legend2_keys_list[2]),  # labels参数，图例上图形对应的标签\n",
    "           loc=\"upper center\",  # loc表示位置\n",
    "           prop=matplotlib.font_manager.FontProperties(size=12))  # prop字体参数\n",
    "# 设置坐标轴的标签label\n",
    "plt.ylabel(\"% lower status of the population\")\n",
    "plt.xlabel(\"average number of rooms per dwelling\")\n",
    "\n",
    "# 显示\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================================\n",
    "真实数据集的异常值检测简介\n",
    "====================================\n",
    "\n",
    "此示例介绍了对真实数据集进行鲁棒协方差估计的必须性。(鲁棒的意思是足够稳定，绝不过拟合。)\n",
    "它对于异常检测(离群值检测)和更好地理解数据结构都是有用的。\n",
    "\n",
    "我们从波士顿住房数据集中选择了两组两个变量的数据子集，\n",
    "以说明可以使用几种离群值检测工具进行哪些分析。\n",
    "出于可视化的目的，我们使用的是2维示例，但是应该指出的是，在高维度上事情并非那么简单。\n",
    "\n",
    "在下面的两个示例来看，主要结论是经验协方差估计(作为一种非稳健的估计)\n",
    "受观测的异构结构的影响很大。尽管鲁棒的协方差估计能够集中于数据分布的主要模式，\n",
    "但它假定数据应该是高斯分布的，从而产生了对数据结构的某种有偏估计，不过在一定程度上还算准确。\n",
    "One-Class SVM不假设数据分布的任何参数形式，因此可以更好地对数据的复杂形状进行建模。\n",
    "\n",
    "第一个例子\n",
    "-------------\n",
    "第一个示例说明了当另外一个簇存在时，鲁棒的协方差估计如何帮助集中在相关簇上。\n",
    "在这里，许多观察结果被混淆为一个，让经验协方差估计效果变差。\n",
    "当然，某些筛选工具能指出存在两个聚类(支持向量机，高斯混合模型，单变量离群值检测……)。\n",
    "但是，如果这是一个高维度的例子，那么所有这些都不容易被应用。\n",
    "\n",
    "第二个例子\n",
    "-------------\n",
    "第二个示例显示了最小协方差鲁棒估计器专注于数据分布的主要模式的能力：\n",
    "尽管由于香蕉形分布而难以估算协方差，但位置似乎已得到很好的估计。\n",
    "无论如何，我们可以消除一些较远的离群点。 One-Class SVM能够捕获真实的数据结构，\n",
    "但是困难在于如何调整其核带宽参数，以便在数据散布矩阵的形状和过滤合数据的风险之间取得良好的折衷。\n",
    "\"\"\"\n",
    "\n",
    "# Author: Virgile Fritsch <virgile.fritsch@inria.fr>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# 载入此项目所需要的库\n",
    "import numpy as np\n",
    "# 椭圆模型拟合,它能拟合出数据的稳健协方差估计，从而为中心数据点拟合出一个椭圆，忽略不和该中心模式相关的点\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM  # 单类支持向量机\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "from sklearn.datasets import load_boston  # 从 sklearn 数据集中导入波士顿房价数据\n",
    "\n",
    "# 获取数据 取数据集里的两个变量，这两个变量的观测组成两类。\n",
    "X1 = load_boston()['data'][:, [8, 10]]  # 将数据分成两个集群\n",
    "X2 = load_boston()['data'][:, [5, 12]]  # 香蕉形\n",
    "\n",
    "# 定义要使用的分类器对象classifiers, 它是一个字典型，\n",
    "# 由Empirical Covariance, Robust Covariance, 单类支持向量机 OCSVM 三个分类器组成。\n",
    "classifiers = {\n",
    "    \"Empirical Covariance\": EllipticEnvelope(  # EmpiricalCovariance是基于最大似然协方差估计的算法\n",
    "        support_fraction=1.,  # 支持原始MCD(最小协方差行列式)估算的点数比例\n",
    "        contamination=0.261),  # 数据集的污染量，即数据集中异常值的比例。\n",
    "    # Robust Covariance是基于最小协方差行列式的算法，是鲁棒协方差估计。\n",
    "    \"Robust Covariance (Minimum Covariance Determinant)\":\n",
    "    EllipticEnvelope(contamination=0.261),\n",
    "        \"OCSVM\": OneClassSVM(nu=0.261,  # 训练误差分数的上限，支持向量分数的下限\n",
    "                             gamma=0.05)}  # 内核系数\n",
    "colors = ['m', 'g', 'b']\n",
    "legend1 = {}\n",
    "legend2 = {}\n",
    "\n",
    "# 使用定义的三个分类器，确定异常点检测边界\n",
    "# ny.meshgrid()从坐标向量中返回坐标矩阵\n",
    "# np.linspace 函数用于创建一个一维数组，数组是一个等差数列构成的\n",
    "# np.linspace(start, stop, num) 目的是在start-stop之间生成num个数\n",
    "# np.c_是按行连接两个矩阵，就是把两矩阵左右相加，要求行数相等\n",
    "xx1, yy1 = np.meQshgrid(np.linspace(-8, 28, 500), np.linspace(3, 40, 500))\n",
    "xx2, yy2 = np.meshgrid(np.linspace(3, 10, 500), np.linspace(-5, 45, 500))\n",
    "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "    plt.figure(1)\n",
    "    clf.fit(X1)  # 模型拟合\n",
    "    Z1 = clf.decision_function(  # decision_function代表的是参数实例到各个类所代表的超平面的距离\n",
    "        np.c_[xx1.ravel(), yy1.ravel()])\n",
    "    Z1 = Z1.reshape(xx1.shape)  # 将Z1的维度指定为xx1的维度\n",
    "    legend1[clf_name] = plt.contour(  # 绘制等高线\n",
    "        xx1, yy1, Z1,  # 使用 xx1 和 yy1 绘制 Z1 的等高线图，指定 Z1 中各值的 x 和 y 坐标\n",
    "        levels=[0],  # 确定轮廓线/区域的数量和位置。\n",
    "        linewidths=2,  # 线的宽度\n",
    "        colors=colors[i])  # 标签的颜色\n",
    "    plt.figure(2)\n",
    "\n",
    "    clf.fit(X2)\n",
    "    Z2 = clf.decision_function(np.c_[xx2.ravel(), yy2.ravel()])\n",
    "    Z2 = Z2.reshape(xx2.shape)\n",
    "    legend2[clf_name] = plt.contour(  # 绘制等高线\n",
    "        xx2, yy2, Z2,  # 使用 xx2 和 yy2 绘制 Z2 的等高线图，指定 Z2 中各值的 x 和 y 坐标\n",
    "        levels=[0], linewidths=2, colors=colors[i])\n",
    "\n",
    "legend1_values_list = list(legend1.values())\n",
    "legend1_keys_list = list(legend1.keys())\n",
    "\n",
    "# 画出结果图，我们会看到一个明显异常的观测点。\n",
    "# 新建一个名叫 Figure1的画图窗口\n",
    "plt.figure(1)  # two clusters\n",
    "plt.title(\"Outlier detection on a real data set (boston housing)\")  # 标题\n",
    "plt.scatter(X1[:, 0], X1[:, 1], color='black')  # 绘制散点\n",
    "bbox_args = dict(boxstyle=\"round\", fc=\"0.8\")\n",
    "arrow_args = dict(arrowstyle=\"->\")\n",
    "# 绘制注解\n",
    "plt.annotate(\"several confounded points\",  # 注释文本内容\n",
    "             xy=(24, 19),  # 被注释的坐标点(箭头点所在的坐标位置)\n",
    "             xycoords=\"data\",  # **coords 指定坐标\n",
    "             textcoords=\"data\",  # data：使用被注释对象的坐标系统(默认)\n",
    "             xytext=(13, 10),  # 注释文字的坐标位置\n",
    "             bbox=bbox_args,  # 为注释文本添加边框\n",
    "             arrowprops=arrow_args)  # 设置指向箭头的参数,参数类型为字典dict\n",
    "# 设置坐标轴的取值范围\n",
    "plt.xlim((xx1.min(), xx1.max()))\n",
    "plt.ylim((yy1.min(), yy1.max()))\n",
    "# 设置 legend 图例\n",
    "plt.legend((legend1_values_list[0].collections[0],  # handles参数，用于指定图例上面的图形\n",
    "            legend1_values_list[1].collections[0],\n",
    "            legend1_values_list[2].collections[0]),\n",
    "           (legend1_keys_list[0], legend1_keys_list[1],\n",
    "            legend1_keys_list[2]),  # labels参数，图例上图形对应的标签\n",
    "           loc=\"upper center\",  # 图例的位置\n",
    "           prop=matplotlib.font_manager.FontProperties(size=12))  # 图例的字体属性\n",
    "# 设置坐标轴的标签label\n",
    "plt.ylabel(\"accessibility to radial highways\")\n",
    "plt.xlabel(\"pupil-teacher ratio by town\")\n",
    "\n",
    "legend2_values_list = list(legend2.values())\n",
    "legend2_keys_list = list(legend2.keys())\n",
    "\n",
    "# 新建一个名叫 Figure2的画图窗口\n",
    "plt.figure(2)  # \"banana\" shape\n",
    "plt.title(\"Outlier detection on a real data set (boston housing)\")  # 标题\n",
    "plt.scatter(X2[:, 0], X2[:, 1], color='black')  # 绘制散点\n",
    "# 设置坐标轴的取值范围\n",
    "plt.xlim((xx2.min(), xx2.max()))\n",
    "plt.ylim((yy2.min(), yy2.max()))\n",
    "# 设置 legend 图例\n",
    "plt.legend((legend2_values_list[0].collections[0],  # handles参数，用于指定图例上面的图形\n",
    "            legend2_values_list[1].collections[0],\n",
    "            legend2_values_list[2].collections[0]),\n",
    "           (legend2_keys_list[0], legend2_keys_list[1],\n",
    "            legend2_keys_list[2]),  # labels参数，图例上图形对应的标签\n",
    "           loc=\"upper center\",  # loc表示位置\n",
    "           prop=matplotlib.font_manager.FontProperties(size=12))  # prop字体参数\n",
    "# 设置坐标轴的标签label\n",
    "plt.ylabel(\"% lower status of the population\")\n",
    "plt.xlabel(\"average number of rooms per dwelling\")\n",
    "\n",
    "# 显示\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda926f92ea88cc4e2a9261c74aed2fab1e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}